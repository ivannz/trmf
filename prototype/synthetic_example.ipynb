{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorizing the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import `TRMFREgressor` which provides scikit-like, but still\n",
    "incomplatible interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trmf import TRMFRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(8945634)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will play with a latent autoregression dataset that we are about to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_components, n_targets, n_order = 120, 4, 16, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating stationary lag polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some roots within the unit cicrle:\n",
    "* if $r \\sim \\mathrm{U}[0, 1]$ and $\\phi \\sim \\mathrm{U}[0, 2\\pi]$ then\n",
    "the complex-values random variable $Z = \\sqrt{r} e^{i \\phi}$ has a uniform\n",
    "distribution within the unit disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = random_state.uniform(0, 1, size=(n_components, n_order))\n",
    "phi = random_state.uniform(0, 2, size=(n_components, n_order)) * np.pi\n",
    "\n",
    "phi /= 4\n",
    "\n",
    "roots = np.sqrt(rad) * (np.cos(phi) + np.sin(phi) * 1.j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, in multivariate calculus the change of variables under integration is performed thus\n",
    "$$\n",
    "\\int_R f(x) dx\n",
    "    = \\int_S\n",
    "        f(g(u)) \\lvert J \\rvert du\n",
    "    \\,, $$\n",
    "where the Jacobian is given by $\\tfrac{\\partial g}{\\partial u^{\\mathrm{T}}}$. Therefore, for\n",
    "any measurable rectangle $A\\times B$ in $\\mathbb{R}^2$ we have\n",
    "$$\n",
    "\\int_0^1 \\int_0^{2\\pi} \\tfrac1{2 \\pi}\n",
    "    1_{A \\times B} \\bigl(\\sqrt{r} \\cos \\phi, \\sqrt{r} \\sin \\phi\\bigr) dr d\\phi\n",
    "    = \\bigl[\n",
    "        x,y = \\sqrt{r} \\cos \\phi, \\sqrt{r} \\sin \\phi,\\, \\det J = \\tfrac12\n",
    "    \\bigr]\n",
    "    % = \\iint_{B[0,1]} \\tfrac1{2 \\pi}\n",
    "    %     1_{A \\times B} \\bigl(x, y\\bigr) 2 \\tfrac12 dx dy\n",
    "    = \\iint_{B[0,1]} \\tfrac1{\\pi} 1_{A \\times B} \\bigl(x, y\\bigr) dx dy\n",
    "    \\,, $$\n",
    "where $B[0, 1] = \\{x\\in \\mathbb{R}^2\\colon \\|x\\|_2 \\leq 1\\}$ and the Jacobian is \n",
    "$$\n",
    "\\det J\n",
    "    = \\begin{vmatrix}\n",
    "        \\tfrac{\\partial x}{\\partial r} & \\tfrac{\\partial x}{\\partial \\phi} \\\\\n",
    "        \\tfrac{\\partial y}{\\partial r} & \\tfrac{\\partial y}{\\partial \\phi} \\\\\n",
    "    \\end{vmatrix}\n",
    "    = \\begin{vmatrix}\n",
    "        \\tfrac1{2\\sqrt{r}} \\cos \\phi & - \\sqrt{r} \\sin \\phi \\\\\n",
    "        \\tfrac1{2\\sqrt{r}} \\sin \\phi &   \\sqrt{r} \\cos \\phi\n",
    "    \\end{vmatrix}\n",
    "    = \\tfrac1{2\\sqrt{r}} \\sqrt{r} \\cos^2 \\phi - \\tfrac1{2\\sqrt{r}} (-\\sqrt{r}) \\sin^2 \\phi\n",
    "    = \\tfrac12 \\cos^2 \\phi + \\tfrac12 \\sin^2 \\phi\n",
    "    \\,. $$\n",
    "Note that the area of $B[0, 1]$ is $r^2 \\pi = 1\\cdot \\pi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to avoid negative autocorrelation, let's confine the roots to the right-half of the unit disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roots.real = np.abs(roots.real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that the complex roots are in conjugate pairs, so that the lag ploynomial has real coefficients.\n",
    "\n",
    "* we keep at least two real roots and fill the rest with conjugate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cplx = max(0, n_order - 1) // 2\n",
    "\n",
    "n_real = n_order - n_cplx * 2\n",
    "\n",
    "roots = np.concatenate([\n",
    "    roots[:, :n_cplx], np.conj(roots[:, :n_cplx]), np.real(roots[:, -n_real:])\n",
    "], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the lag polynomial we have the following:\n",
    "$$\n",
    "    \\Phi(L)\n",
    "        = 1 - \\sum_{k=1}^p \\phi_k L^k\n",
    "        = L^p \\Bigl(\n",
    "            L^{-p} - \\sum_{k=1}^p \\phi_k L^{k-p}\n",
    "        \\Bigr)\n",
    "        = L^p \\Bigl(\n",
    "            z^p + \\sum_{k=1}^p (-\\phi_k) z^{p-k}\n",
    "        \\Bigr) \\Big\\vert_{z = L^{-1}}\n",
    "        = L^p \\prod_{k=1}^p (z - z_k) \\Big\\vert_{z = L^{-1}}\n",
    "        = \\prod_{k=1}^p (1 - z_k L)\n",
    "    \\,, $$\n",
    "\n",
    "where $(zk)_{k=1}^p\\in \\mathbb{C}$ are the roots of the $p$-th order polynomial\n",
    "$q(z) = z^p - \\phi_1 z^{p-1} - \\cdots - \\phi_p = \\phi_0 z^p + \\sum_{k=1}^p (-\\phi_k) z^{p-k}$\n",
    "with $\\phi_0 = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following formal series in terms of the lag operator $L$, provided $\\lvert z \\rvert < 1$, $z\\in \\mathbb{C}$:\n",
    "$$\n",
    "    (1 - z L)^{-1} = \\sum_{k\\geq 0} z^k L^k\n",
    "    \\,. $$\n",
    "If each $z_k$ is such, then its associated order-$1$ lag polynomial $(1-z_k L)$ is invertible. Since the lag operators\n",
    "commute, the whole lag polynomial $\\Phi(L)$ is invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, if all $z_k\\in \\mathbb{C}$ lie inside the unit circle, then the lag polynomial represents a stationary (causal) autoregression process of order $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the roots to the ploynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `np.poly` computes the coefficients of a polynomial $q(z)$ which has roots $(z_k)_{k=1}^p\\in \\mathbb{C}$,\n",
    "where\n",
    "$$\n",
    "q(z)\n",
    "    = \\alpha_0 z^p + \\sum_{k=1}^p \\alpha_k z^{p - k}\n",
    "    = \\prod_{k=1}^p (z - z_k)\n",
    "    \\,, $$\n",
    "with $\\alpha_0=1$. Therefore to the get the coefficients of the corresponding lag\n",
    "polynomial we just need to map $(z_k)_{k=1}^p \\mapsto (\\alpha_k)_{k=0}^p$ and then\n",
    "flip the sign of each one $\\phi_k = - \\alpha_k$ for $k=1,\\,\\ldots,\\,p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_phi = np.stack([- np.poly(zeroes)[1:] for zeroes in roots], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the roots are within the unit circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([[c] * n_order for c in [\"C0\", \"C1\", \"C2\", \"C3\"]]).ravel()\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, projection=\"polar\")\n",
    "ax.scatter(np.angle(roots), np.abs(roots), c=colors, s=50)  #, c=colors, s=area, cmap='hsv', alpha=0.75)\n",
    "ax.set_rlim(0, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now $y_{t-p:t}$ returns $y_{t-p}, y_{t-p+1},\\,\\ldots,\\,y_{t-1}$, which means that\n",
    "to get the next $y_t$ we must multiply each by $\\phi_p,\\,\\ldots,\\,\\phi_1$ respectively,\n",
    "i.e. $\\phi$ in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ar_coef = real_phi[:, ::-1].copy()\n",
    "\n",
    "plt.imshow(real_ar_coef, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the autoregressive process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = random_state.normal(scale=0.1, size=(n_samples, n_components))\n",
    "for t in range(n_order, n_samples):\n",
    "    # the columns in `real_ar_coef` are in ordered from $p$, the least\n",
    "    #  recent lag, up to $1$, the most recent lag.\n",
    "    noise[t] += np.einsum(\"il,li->i\", real_ar_coef, noise[t-n_order:t])\n",
    "#     noise[t] = np.einsum(\"il,li->i\", real_ar_coef, noise[t-n_order:t])\n",
    "\n",
    "real_factors = noise.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate factor loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_loadings = random_state.uniform(-1, 2, size=(n_components, n_targets))\n",
    "real_loadings = np.maximum(real_loadings, 0)\n",
    "\n",
    "noise = random_state.normal(scale=0.1, size=(n_samples, n_targets))\n",
    "\n",
    "mean = random_state.normal(50, scale=0, size=(1, n_targets))\n",
    "targets = np.dot(real_factors, real_loadings) + noise + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = (n_components + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 1.5*n_rows),\n",
    "                         sharex=True, sharey=False)\n",
    "for j, ax in zip(range(n_components), axes.ravel()):\n",
    "    ax.plot(real_factors[:, j])\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the observed series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = (n_targets + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 1.5*n_rows), sharex=True, sharey=False)\n",
    "for j, ax in zip(range(n_targets), axes.ravel()):\n",
    "    ax.plot(targets[:, j], lw=2)\n",
    "    ax.set_title(f\"\"\"target {j}\"\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(real_loadings, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linalg.norm(real_loadings, ord=1, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the synthetic data into train and test periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_targets, test_targets = train_test_split(\n",
    "    targets, test_size=.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Never forget to centre and scale the train dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scl = StandardScaler(with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a model with more factors but the same AR$(p)$ latent process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_order, n_components = 8, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original setup: no intercept and no regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Z, C_F, C_phi = 5e-2, 5e-1, 1e-6\n",
    "eta_Z, eta_F, adj = 0.95, 0.0, None\n",
    "C_B, regressors, fit_intercept = 0., None, True\n",
    "\n",
    "n_max_mf_iter = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better results: fir intercept, place more emphasis on latent autoregression,\n",
    "regularize the autoregression coefficients more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Z, C_F, C_phi = 5e-2, 5e-1, 1e-2\n",
    "eta_Z, eta_F, adj = 0.99, 0.0, None\n",
    "C_B, regressors, fit_intercept = 0., None, True\n",
    "n_max_mf_iter = 5  # default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf = TRMFRegressor(n_components, n_order, C_Z=C_Z, C_F=C_F, C_phi=C_phi,\n",
    "                     eta_Z=eta_Z, eta_F=eta_F, adj=adj, C_B=C_B,\n",
    "                     fit_regression=False, fit_intercept=fit_intercept,\n",
    "                     nonnegative_factors=True, n_max_mf_iter=n_max_mf_iter)\n",
    "\n",
    "YY = scl.fit_transform(train_targets)\n",
    "trmf.fit(YY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trmf.loadings_, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trmf.ar_coef_, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trmf.intercept_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trmf.coef_, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf.loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf.ar_coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the forecast horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ahead, n_horizon = len(test_targets), 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast the latent factors and paste them with the ones inferred from the train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_factors = trmf.forecast_factors(n_ahead + n_horizon)\n",
    "\n",
    "factors = np.concatenate([trmf.factors_, forecast_factors], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute train estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated = np.dot(trmf.factors_, trmf.loadings_)\n",
    "estimated += trmf.intercept_\n",
    "\n",
    "if regressors is not None:\n",
    "    estimated += np.dot(regressors, trmf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which regressors to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_features = None\n",
    "if regressors is not None:\n",
    "    predicted_features = np.concatenate([\n",
    "        test_features, np.zeros((n_horizon, test_features.shape[1])),\n",
    "    ], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predictions:\n",
    "$$ \n",
    "    \\hat{Y}_{t+h\\mid t}\n",
    "        = \\hat{X}_{t+h\\mid t} F\n",
    "    \\,,\\quad\n",
    "    \\hat{X}_{t+h\\mid t}\n",
    "        = \\sum_{k=1}^p \\mathop{\\text{diag}}\\bigl(\\hat{\\theta}_{\\cdot k}\\bigr) \\hat{X}_{t+h-k\\mid t}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = trmf.predict(X=predicted_features, n_ahead=n_ahead + n_horizon)\n",
    "\n",
    "# paste the train targets and the dynamic forecast\n",
    "predicted = np.concatenate([estimated, predicted], axis=0)\n",
    "\n",
    "predicted_target = scl.inverse_transform(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the dynamics of the latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = (n_components + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 1.5*n_rows),\n",
    "                         sharex=True, sharey=False)\n",
    "\n",
    "for j, ax in zip(range(n_components), axes.flat):\n",
    "    ax.plot(factors[:-(n_ahead + n_horizon), j], lw=2)\n",
    "    ax.plot(factors[:-n_horizon, j], zorder=-1)\n",
    "    ax.plot(factors[:, j], zorder=-2, alpha=0.5)\n",
    "\n",
    "for ax in axes.flat[n_components:]:\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    ax.plot([0, len(factors)], [y_min, y_max], c=\"k\", lw=2, alpha=.25)\n",
    "    ax.plot([0, len(factors)], [y_max, y_min], c=\"k\", lw=2, alpha=.25)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_predicted_target = predicted_target[:-n_ahead-n_horizon:]\n",
    "\n",
    "trmf_mse = mean_squared_error(train_targets, train_predicted_target)\n",
    "lastknown_mse = mean_squared_error(train_targets[1:], train_targets[:-1])\n",
    "\n",
    "\n",
    "print(f\"\"\"train >>>\\nTRMF: {trmf_mse}\\nRunning Last: {lastknown_mse}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if n_horizon > 0:\n",
    "    test_predicted_target = predicted_target[-n_ahead-n_horizon:-n_horizon]\n",
    "else:\n",
    "    test_predicted_target = predicted_target[-n_ahead:]\n",
    "\n",
    "trmf_mse = mean_squared_error(test_targets, test_predicted_target)\n",
    "last_mse = mean_squared_error(test_targets, train_targets[[-1] * len(test_targets)])\n",
    "lastknown_mse = mean_squared_error(test_targets[1:], test_targets[:-1])\n",
    "\n",
    "\n",
    "print(f\"\"\"test >>>\\nTRMF: {trmf_mse}\\nLast train: {last_mse}\\nRunning Last: {lastknown_mse}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_cols = 4\n",
    "n_rows = (n_targets + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 1.5 * n_rows),\n",
    "                         sharex=True, sharey=False)\n",
    "\n",
    "for j, ax in zip(range(n_targets), axes.flat):\n",
    "    ax.plot(targets[:, j], lw=2)\n",
    "    ax.plot(predicted_target[:, j], zorder=2)\n",
    "    ax.axvspan(0, len(train_targets) - 1, color=\"k\", zorder=-1, alpha=0.05)\n",
    "    ax.set_title(f\"\"\"target {j}\"\"\")\n",
    "\n",
    "for ax in axes.flat[n_targets:]:\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    ax.plot([0, len(predicted_target)], [y_min, y_max], c=\"k\", lw=2, alpha=.25)\n",
    "    ax.plot([0, len(predicted_target)], [y_max, y_min], c=\"k\", lw=2, alpha=.25)\n",
    "#     ax.set_frame_on(False) ; ax.set_xticks([]) ; ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact the model will be reestimated upon arrival of new data, so\n",
    "this validation strategy, where we compare dynamic forecasts with\n",
    "the actual data is incompatible with the usage scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trmf.factors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((YY.shape[0], 0)) if regressors is None else regressors\n",
    "fitted = np.dot(trmf.factors_, trmf.loadings_) + np.dot(X, trmf.coef_) + trmf.intercept_\n",
    "\n",
    "plt.plot(np.abs(fitted - YY).std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"\"\"STOP!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.zeros_like(targets[:, :2])\n",
    "features[2:] = targets[:-2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.erdos_renyi_graph(n_targets, 0.2, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = nx.adjacency_matrix(G)\n",
    "adj = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
