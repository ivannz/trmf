{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorizing the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import `TRMFREgressor` which provides scikit-like, but still\n",
    "incomplatible interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trmf import TRMFRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = np.random.RandomState(8945634)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will play with a latent autoregression dataset that we are about to generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_components, n_targets, n_order = 120, 4, 16, 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating stationary lag polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some roots within the unit cicrle:\n",
    "* if $r \\sim \\mathrm{U}[0, 1]$ and $\\phi \\sim \\mathrm{U}[0, 2\\pi]$ then\n",
    "the complex-values random variable $Z = \\sqrt{r} e^{i \\phi}$ has a uniform\n",
    "distribution within the unit disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = random_state.uniform(0, 1, size=(n_components, n_order))\n",
    "phi = random_state.uniform(0, 2, size=(n_components, n_order)) * np.pi\n",
    "\n",
    "phi /= 4\n",
    "\n",
    "roots = np.sqrt(rad) * (np.cos(phi) + np.sin(phi) * 1.j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, in multivariate calculus the change of variables under integration is performed thus\n",
    "$$\n",
    "\\int_R f(x) dx\n",
    "    = \\int_S\n",
    "        f(g(u)) \\lvert J \\rvert du\n",
    "    \\,, $$\n",
    "where the Jacobian is given by $\\tfrac{\\partial g}{\\partial u^{\\mathrm{T}}}$. Therefore, for\n",
    "any measurable rectangle $A\\times B$ in $\\mathbb{R}^2$ we have\n",
    "$$\n",
    "\\int_0^1 \\int_0^{2\\pi} \\tfrac1{2 \\pi}\n",
    "    1_{A \\times B} \\bigl(\\sqrt{r} \\cos \\phi, \\sqrt{r} \\sin \\phi\\bigr) dr d\\phi\n",
    "    = \\bigl[\n",
    "        x,y = \\sqrt{r} \\cos \\phi, \\sqrt{r} \\sin \\phi,\\, \\det J = \\tfrac12\n",
    "    \\bigr]\n",
    "    % = \\iint_{B[0,1]} \\tfrac1{2 \\pi}\n",
    "    %     1_{A \\times B} \\bigl(x, y\\bigr) 2 \\tfrac12 dx dy\n",
    "    = \\iint_{B[0,1]} \\tfrac1{\\pi} 1_{A \\times B} \\bigl(x, y\\bigr) dx dy\n",
    "    \\,, $$\n",
    "where $B[0, 1] = \\{x\\in \\mathbb{R}^2\\colon \\|x\\|_2 \\leq 1\\}$ and the Jacobian is \n",
    "$$\n",
    "\\det J\n",
    "    = \\begin{vmatrix}\n",
    "        \\tfrac{\\partial x}{\\partial r} & \\tfrac{\\partial x}{\\partial \\phi} \\\\\n",
    "        \\tfrac{\\partial y}{\\partial r} & \\tfrac{\\partial y}{\\partial \\phi} \\\\\n",
    "    \\end{vmatrix}\n",
    "    = \\begin{vmatrix}\n",
    "        \\tfrac1{2\\sqrt{r}} \\cos \\phi & - \\sqrt{r} \\sin \\phi \\\\\n",
    "        \\tfrac1{2\\sqrt{r}} \\sin \\phi &   \\sqrt{r} \\cos \\phi\n",
    "    \\end{vmatrix}\n",
    "    = \\tfrac1{2\\sqrt{r}} \\sqrt{r} \\cos^2 \\phi - \\tfrac1{2\\sqrt{r}} (-\\sqrt{r}) \\sin^2 \\phi\n",
    "    = \\tfrac12 \\cos^2 \\phi + \\tfrac12 \\sin^2 \\phi\n",
    "    \\,. $$\n",
    "Note that the area of $B[0, 1]$ is $r^2 \\pi = 1\\cdot \\pi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to avoid negative autocorrelation, let's confine the roots to the right-half of the unit disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roots.real = np.abs(roots.real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that the complex roots are in conjugate pairs, so that the lag ploynomial has real coefficients.\n",
    "\n",
    "* we keep at least two real roots and fill the rest with conjugate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cplx = max(0, n_order - 1) // 2\n",
    "\n",
    "n_real = n_order - n_cplx * 2\n",
    "\n",
    "roots = np.concatenate([\n",
    "    roots[:, :n_cplx], np.conj(roots[:, :n_cplx]), np.real(roots[:, -n_real:])\n",
    "], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the lag polynomial we have the following:\n",
    "$$\n",
    "    \\Phi(L)\n",
    "        = 1 - \\sum_{k=1}^p \\phi_k L^k\n",
    "        = L^p \\Bigl(\n",
    "            L^{-p} - \\sum_{k=1}^p \\phi_k L^{k-p}\n",
    "        \\Bigr)\n",
    "        = L^p \\Bigl(\n",
    "            z^p + \\sum_{k=1}^p (-\\phi_k) z^{p-k}\n",
    "        \\Bigr) \\Big\\vert_{z = L^{-1}}\n",
    "        = L^p \\prod_{k=1}^p (z - z_k) \\Big\\vert_{z = L^{-1}}\n",
    "        = \\prod_{k=1}^p (1 - z_k L)\n",
    "    \\,, $$\n",
    "\n",
    "where $(zk)_{k=1}^p\\in \\mathbb{C}$ are the roots of the $p$-th order polynomial\n",
    "$q(z) = z^p - \\phi_1 z^{p-1} - \\cdots - \\phi_p = \\phi_0 z^p + \\sum_{k=1}^p (-\\phi_k) z^{p-k}$\n",
    "with $\\phi_0 = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following formal series in terms of the lag operator $L$, provided $\\lvert z \\rvert < 1$, $z\\in \\mathbb{C}$:\n",
    "$$\n",
    "    (1 - z L)^{-1} = \\sum_{k\\geq 0} z^k L^k\n",
    "    \\,. $$\n",
    "If each $z_k$ is such, then its associated order-$1$ lag polynomial $(1-z_k L)$ is invertible. Since the lag operators\n",
    "commute, the whole lag polynomial $\\Phi(L)$ is invertible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, if all $z_k\\in \\mathbb{C}$ lie inside the unit circle, then the lag polynomial represents a stationary (causal) autoregression process of order $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the roots to the ploynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `np.poly` computes the coefficients of a polynomial $q(z)$ which has roots $(z_k)_{k=1}^p\\in \\mathbb{C}$,\n",
    "where\n",
    "$$\n",
    "q(z)\n",
    "    = \\alpha_0 z^p + \\sum_{k=1}^p \\alpha_k z^{p - k}\n",
    "    = \\prod_{k=1}^p (z - z_k)\n",
    "    \\,, $$\n",
    "with $\\alpha_0=1$. Therefore to the get the coefficients of the corresponding lag\n",
    "polynomial we just need to map $(z_k)_{k=1}^p \\mapsto (\\alpha_k)_{k=0}^p$ and then\n",
    "flip the sign of each one $\\phi_k = - \\alpha_k$ for $k=1,\\,\\ldots,\\,p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_phi = np.stack([- np.poly(zeroes)[1:] for zeroes in roots], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure the roots are within the unit circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([[c] * n_order for c in [\"C0\", \"C1\", \"C2\", \"C3\"]]).ravel()\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "\n",
    "ax = fig.add_subplot(111, projection=\"polar\")\n",
    "ax.scatter(np.angle(roots), np.abs(roots), c=colors, s=50)\n",
    "ax.set_rlim(0, 1.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now $y_{t-p:t}$ returns $y_{t-p}, y_{t-p+1},\\,\\ldots,\\,y_{t-1}$, which means that\n",
    "to get the next $y_t$ we must multiply each by $\\phi_p,\\,\\ldots,\\,\\phi_1$ respectively,\n",
    "i.e. $\\phi$ in reverse order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ar_coef = real_phi[:, ::-1].copy()\n",
    "\n",
    "plt.imshow(real_ar_coef, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate the autoregressive process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# this is suitable for filtering, aka onte step ahead in-sample prediction\n",
    "np.correlate(noise_copy[:-1, 0], real_ar_coef[0], mode=\"valid\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = random_state.normal(scale=0.1, size=(n_samples, n_components))\n",
    "for t in range(n_order, n_samples):\n",
    "    # the columns in `real_ar_coef` are in ordered from $p$, the least\n",
    "    #  recent lag, up to $1$, the most recent lag.\n",
    "    noise[t] += np.einsum(\"il,li->i\", real_ar_coef, noise[t-n_order:t])\n",
    "#     noise[t] = np.einsum(\"il,li->i\", real_ar_coef, noise[t-n_order:t])\n",
    "\n",
    "real_factors = noise.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate factor loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_loadings = random_state.uniform(-1, 2, size=(n_components, n_targets))\n",
    "real_loadings = np.maximum(real_loadings, 0)\n",
    "\n",
    "noise = random_state.normal(scale=0.1, size=(n_samples, n_targets))\n",
    "\n",
    "mean = random_state.normal(50, scale=0, size=(1, n_targets))\n",
    "targets = mean + np.dot(real_factors, real_loadings) + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = (n_components + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 1.5*n_rows),\n",
    "                         sharex=True, sharey=False)\n",
    "for j, ax in zip(range(n_components), axes.ravel()):\n",
    "    ax.plot(real_factors[:, j])\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the observed series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = (n_targets + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 1.5*n_rows), sharex=True, sharey=True)\n",
    "for j, ax in zip(range(n_targets), axes.ravel()):\n",
    "    ax.plot(targets[:, j], lw=2)\n",
    "    ax.set_title(f\"\"\"target {j}\"\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(real_loadings, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linalg.norm(real_loadings, ord=1, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tempiral regularized matrix factorization can model only\n",
    "stationary latent time series. Thus integrated processes\n",
    "break the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = targets.cumsum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorize the matrix with TRMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the synthetic data into train and test periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_targets, test_targets = train_test_split(\n",
    "    targets, test_size=.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Never forget to centre and scale the train dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scl = StandardScaler(with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a model with more factors but the same AR$(p)$ latent process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_order, n_components = 8, 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original setup: no intercept and no regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Z, C_F, C_phi = 5e-2, 5e-1, 1e-6\n",
    "eta_Z, eta_F, adj = 0.95, 0.0, None\n",
    "C_B, regressors, fit_intercept = 0., None, True\n",
    "\n",
    "n_max_mf_iter = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better results: fit intercept, place more emphasis on latent autoregression,\n",
    "regularize the autoregression coefficients more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Z, C_F, C_phi = 5e-2, 5e-1, 1e-2\n",
    "eta_Z, eta_F, adj = 0.99, 0.0, None\n",
    "C_B, regressors, fit_intercept = 0., None, True\n",
    "n_max_mf_iter = 5  # default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf = TRMFRegressor(n_components, n_order, C_Z=C_Z, C_F=C_F, C_phi=C_phi,\n",
    "                     eta_Z=eta_Z, eta_F=eta_F, adj=adj, C_B=C_B,\n",
    "                     fit_regression=False, fit_intercept=fit_intercept,\n",
    "                     nonnegative_factors=True, n_max_mf_iter=n_max_mf_iter)\n",
    "\n",
    "YY = scl.fit_transform(train_targets)\n",
    "trmf.fit(YY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = {\n",
    "    'n_order': 7,\n",
    "    'n_components': 12,\n",
    "    'eta_Z': 0.95,\n",
    "    'C_phi': 0.1,\n",
    "    'C_Z': 10.0,\n",
    "    'C_F': 0.01,\n",
    "}\n",
    "\n",
    "trmf = TRMFRegressor(**par, eta_F=0., adj=None, C_B=0., fit_regression=False,\n",
    "                     fit_intercept=True, nonnegative_factors=True, n_max_mf_iter=5)\n",
    "\n",
    "YY = scl.fit_transform(train_targets)\n",
    "trmf.fit(YY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trmf.loadings_, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trmf.ar_coef_, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trmf.intercept_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trmf.coef_, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf.loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf.ar_coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the forecast horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ahead, n_horizon = len(test_targets), 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the roots of the lag polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roots = 1 / np.stack([np.roots(np.r_[-coef_, 1]) for coef_ in trmf.ar_coef_], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reciprocals of the roots should lie within the $\\mathbb{C}$ unit circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_colors = plt.cm.plasma(np.linspace(0, 1, num=trmf.n_components))\n",
    "colors = np.repeat(base_colors, trmf.n_order, axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, projection=\"polar\")\n",
    "\n",
    "ax.scatter(np.angle(roots), np.abs(roots), c=colors, s=50)\n",
    "ax.set_rlim(0, 1.1)\n",
    "\n",
    "# fig.savefig(f\"./factor_ar_roots.pdf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the in-sample $AR(p)$ filter: the would-be predicted value of $y_t$\n",
    "$$ \\hat{y}_{t\\mid t-1}\n",
    "    = \\sum_{k=1}^p \\phi_k y_{t-k}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_sample_filter = np.stack([\n",
    "    np.correlate(y[:-1], phi, mode=\"valid\")  # phi is in the correct order\n",
    "    for y, phi in zip(trmf.factors_.T, trmf.ar_coef_)\n",
    "], axis=1)\n",
    "\n",
    "in_smaple_forecast = np.concatenate([\n",
    "    trmf.factors_[:trmf.n_order], in_sample_filter,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the in-sample $R^2$ score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_factor_scores = r2_score(\n",
    "    trmf.factors_[trmf.n_order:], in_smaple_forecast[trmf.n_order:],\n",
    "    multioutput='raw_values')\n",
    "\n",
    "\n",
    "plt.title(\"$R^2$ score of the autoregression\")\n",
    "plt.plot(r2_factor_scores)\n",
    "\n",
    "# plt.savefig(f\"./factor_insample_r2.pdf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the factors by their in-sample $R^2$ score from best to worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_order = np.argsort(r2_factor_scores)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicitly compute the factor forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_forecast = trmf.forecast_factors(n_ahead + n_horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste them with the ones inferred from the train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_pasted = np.concatenate([trmf.factors_, dynamic_forecast], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste and plot them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_forecast = np.concatenate([in_smaple_forecast, dynamic_forecast], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a quilt-plot of the recovred factors, their in-sample forecasts and dynamic out-of-sample forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, floor, ceil\n",
    "\n",
    "n_plots, aspect = len(factor_order), (4, 3)\n",
    "\n",
    "n_rows = round(sqrt(aspect[1] * float(n_plots) / aspect[0]) + 0.15)\n",
    "n_cols = round(sqrt(aspect[0] * float(n_plots) / aspect[1]) + 0.15)\n",
    "\n",
    "coef_w, coef_h = 3, 2\n",
    "\n",
    "figsize = n_cols * coef_w, n_rows * coef_h\n",
    "\n",
    "fig, axes = plt.subplots(nrows=n_rows, ncols=n_cols, squeeze=False,\n",
    "                         sharex=True, sharey=True,\n",
    "                         figsize=figsize, facecolor=\"white\", dpi=320)\n",
    "\n",
    "# plot the datasets\n",
    "for j, ax in zip(factor_order, axes.flat):\n",
    "    ax.set_title(f\"fc. {j} ({r2_factor_scores[j]:1.2f})\")\n",
    "\n",
    "    l1, = ax.plot(trmf.factors_[:, j], lw=2)\n",
    "    l2, = ax.plot(factor_forecast[:-(n_ahead + n_horizon), j],\n",
    "                  zorder=2, alpha=0.75, lw=2)\n",
    "    l3, = ax.plot(factor_forecast[:, j],\n",
    "                  zorder=1, alpha=0.5, lw=1)\n",
    "# end for\n",
    "\n",
    "# reset all axes\n",
    "for ax in axes.flat[n_plots:]:\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.plot([0, len(factor_forecast)], [y_min, y_max], c=\"k\", lw=2, alpha=.25)\n",
    "    ax.plot([0, len(factor_forecast)], [y_max, y_min], c=\"k\", lw=2, alpha=.25)\n",
    "# end for\n",
    "\n",
    "ax.legend(*zip((l1, \"estimate\"), (l2, \"forecast\")), loc=\"best\")\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(f\"./factor_forcast_best_{ff}.pdf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and in-sample performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute train estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated = np.dot(trmf.factors_, trmf.loadings_)\n",
    "estimated += trmf.intercept_\n",
    "\n",
    "if regressors is not None:\n",
    "    # regressors = np.empty((len(trmf.factors_), 0))\n",
    "    estimated += np.dot(regressors, trmf.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which regressors to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_features = None\n",
    "\n",
    "if regressors is not None:\n",
    "    predicted_features = np.concatenate([\n",
    "        test_features, np.zeros((n_horizon, test_features.shape[1])),\n",
    "    ], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the predictions:\n",
    "$$ \n",
    "    \\hat{Y}_{t+h\\mid t}\n",
    "        = \\hat{X}_{t+h\\mid t} F\n",
    "    \\,,\\quad\n",
    "    \\hat{X}_{t+h\\mid t}\n",
    "        = \\sum_{k=1}^p \\mathop{\\text{diag}}\\bigl(\\hat{\\theta}_{\\cdot k}\\bigr) \\hat{X}_{t+h-k\\mid t}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = trmf.predict(X=predicted_features, n_ahead=n_ahead + n_horizon)\n",
    "\n",
    "# paste the train targets and the dynamic forecast\n",
    "predicted = np.concatenate([estimated, predicted], axis=0)\n",
    "\n",
    "predicted_target = scl.inverse_transform(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the $R^2$ scores on the train for the targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predicted_target = predicted_target[:-n_ahead-n_horizon:]\n",
    "r2_target_score = r2_score(train_targets, train_predicted_target,\n",
    "                           multioutput=\"raw_values\")\n",
    "\n",
    "# plt.plot(np.abs(fitted - YY).std(axis=0))\n",
    "plt.title(\"$R^2$ score of the reconstruction\")\n",
    "plt.plot(r2_target_score)\n",
    "\n",
    "# plt.savefig(f\"./target_insample_r2.pdf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "trmf_mse = mean_squared_error(train_targets, train_predicted_target)\n",
    "lastknown_mse = mean_squared_error(train_targets[1:], train_targets[:-1])\n",
    "\n",
    "\n",
    "print(f\"\"\"train >>>\\nTRMF: {trmf_mse}\\nRunning Last: {lastknown_mse}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the $R^2$ scores on the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_horizon > 0:\n",
    "    test_predicted_target = predicted_target[-n_ahead-n_horizon:-n_horizon]\n",
    "else:\n",
    "    test_predicted_target = predicted_target[-n_ahead:]\n",
    "\n",
    "r2_target_test_score = r2_score(test_targets, test_predicted_target,\n",
    "                                multioutput=\"raw_values\")\n",
    "\n",
    "plt.title(\"$R^2$ score the holdout\")\n",
    "plt.plot(r2_target_test_score)\n",
    "\n",
    "# plt.savefig(f\"./target_test_r2.pdf\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trmf_mse = mean_squared_error(test_targets, test_predicted_target)\n",
    "last_mse = mean_squared_error(test_targets, train_targets[[-1] * len(test_targets)])\n",
    "lastknown_mse = mean_squared_error(test_targets[1:], test_targets[:-1])\n",
    "\n",
    "\n",
    "print(f\"\"\"test >>>\\nTRMF: {trmf_mse}\\n\"\"\"\n",
    "      f\"\"\"Last train: {last_mse}\\n\"\"\"\n",
    "      f\"\"\"Running Last: {lastknown_mse}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the targets by their in-sample $R^2$ score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_order = np.argsort(r2_target_test_score)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tile them on one canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_cols = 4\n",
    "n_rows = (n_targets + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 1.5 * n_rows),\n",
    "                         sharex=True, sharey=True)\n",
    "\n",
    "for j, ax in zip(target_order, axes.flat):\n",
    "    ax.plot(targets[:, j], lw=2)\n",
    "    ax.plot(predicted_target[:, j], zorder=2)\n",
    "    ax.axvspan(0, len(train_targets) - 1, color=\"k\", zorder=-1, alpha=0.05)\n",
    "    ax.set_title(f\"\"\"target {j} ({r2_target_score[j]:4.2f}, {r2_target_test_score[j]:4.2f})\"\"\")\n",
    "\n",
    "for ax in axes.flat[n_targets:]:\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    ax.plot([0, len(predicted_target)], [y_min, y_max], c=\"k\", lw=2, alpha=.25)\n",
    "    ax.plot([0, len(predicted_target)], [y_max, y_min], c=\"k\", lw=2, alpha=.25)\n",
    "#     ax.set_frame_on(False) ; ax.set_xticks([]) ; ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact the model will be reestimated upon arrival of new data, so\n",
    "this validation strategy, where we compare dynamic forecasts with\n",
    "the actual data is incompatible with the usage scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"\"\"STOP!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search over the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a grid for studying the effects the parameters on the test mutli-step ahead forecast accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParameterGrid(dict(\n",
    "    n_components=np.r_[1:17],\n",
    "    n_order=np.r_[1:17],\n",
    "    C_Z=np.logspace(-2, 1, num=4),\n",
    "    C_F=np.logspace(-2, 1, num=4),\n",
    "    C_phi=np.logspace(-2, 1, num=4),\n",
    "    eta_Z=np.linspace(0.05, 0.95, num=10),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creat the base instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = TRMFRegressor(n_components=1, n_order=0, fit_regression=False,\n",
    "                     fit_intercept=True, nonnegative_factors=True, n_max_mf_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and a data transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = StandardScaler(with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper fit function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def helper(par, train, test, base=base,\n",
    "           transformer=transformer):\n",
    "    # clone, set parameters and fit\n",
    "    trmf = clone(base).set_params(**par).fit(train)\n",
    "    \n",
    "    # predict and return\n",
    "    pred = transformer.inverse_transform(\n",
    "        trmf.predict(n_ahead=len(test)))\n",
    "\n",
    "    return par, mean_squared_error(test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the grid search in parallel on all virtual cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip, time\n",
    "\n",
    "if False:\n",
    "    # Get a time stamp and a name of the storage\n",
    "    dttm = time.strftime(\"%Y%m%d%H%M%S\")\n",
    "    filename = f\"./synth_results_{dttm}.gz\"\n",
    "    print(f\"results to be saved to {filename}\")\n",
    "\n",
    "    # pretransform the train dataset\n",
    "    X = transformer.fit_transform(train_targets)\n",
    "\n",
    "    # run the experiment in parallel\n",
    "    par_ = Parallel(n_jobs=-1, verbose=1)\n",
    "    results = par_(delayed(helper)(par, X, test_targets) for par in grid)\n",
    "\n",
    "    # dump the results to disk\n",
    "    with gzip.open(filename, \"w\", compresslevel=6) as fout:\n",
    "        pickle.dump(results, fout)\n",
    "# end if"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`[Parallel(n_jobs=-1)]: Done 163840 out of 163840 | elapsed: 559.7min finished`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the experiment results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"results\" not in globals():\n",
    "    filename = \"./synth_results_20180906004401.gz\"\n",
    "    assert os.path.exists(filename), \\\n",
    "        \"\"\"Done 163840 out of 163840 | elapsed: 559.7min finished\"\"\"\n",
    "\n",
    "    with gzip.open(filename, \"r\") as fin:\n",
    "        results = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape into a pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# keys = set(k for g in grid.param_grid for k in g.keys())\n",
    "keys = ['n_order', 'n_components', 'eta_Z', 'C_phi', 'C_Z', 'C_F']\n",
    "\n",
    "data = dict((tuple(par[k] for k in keys), rmse,) for par, rmse in results)\n",
    "sr = pd.Series(data, name=\"rmse\").sort_index().rename_axis(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the results into a data cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = sr.values.reshape(*[len(grid.param_grid[0][k]) for k in keys])\n",
    "\n",
    "stepping = [grid.param_grid[0][k] for k in keys]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the flat index of the smallest value\n",
    "flat_index = np.argmin(cube)\n",
    "\n",
    "# ... and unravel into into a multidimensional index\n",
    "index = np.unravel_index(flat_index, cube.shape)\n",
    "\n",
    "# collect the best paramaters from the grid\n",
    "best_ = {k: grid.param_grid[0][k][i] for k, i in zip(keys, index)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_, cube[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the tightness of the parameters around the best:\n",
    "take all settings with the rmse within one standard deviation\n",
    "of the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = np.quantile(cube, 0.001)\n",
    "indices = np.unravel_index(np.flatnonzero(cube <= threshold), cube.shape)\n",
    "\n",
    "df_sens = pd.DataFrame({k: s[ii] for k, s, ii in zip(keys, stepping, indices)})\n",
    "df_sens[\"rmse\"] = cube[indices]\n",
    "\n",
    "df_sens = df_sens.sort_values(\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect top 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens.head(n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meian among the lower $0.1\\%$ quantile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the hyperparameter modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sens.apply({\n",
    "    \"C_F\": np.log10, \"C_Z\": np.log10, \"C_phi\": np.log10,\n",
    "    \"n_order\": lambda x: x, \"n_components\": lambda x: x,\n",
    "    \"eta_Z\": lambda x: x, \"rmse\": lambda x: x\n",
    "}).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chos the x-y-z axes to plot the slices of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install pyqt -n py37 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ('C_F', 'log'), ('C_Z', 'log'), ('n_order', 'lin')\n",
    "# ax = ('C_F', 'log'), ('C_Z', 'log'), ('eta_Z', 'lin')\n",
    "\n",
    "# ax = ('n_order', 'lin'), ('n_components', 'lin'), ('C_Z', 'log')\n",
    "\n",
    "# ax = ('C_F', 'log'), ('C_Z', 'log'), ('C_phi', 'log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ('n_order', 'lin'), ('n_components', 'lin'), ('eta_Z', 'lin')\n",
    "# ax = ('n_order', 'lin'), ('n_components', 'lin'), ('C_phi', 'log')\n",
    "# ax = ('n_order', 'lin'), ('n_components', 'lin'), ('C_F', 'log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the axis indices and the meshgrid to plot on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lx, ly, lz), (sx, sy, sz) = zip(*ax)\n",
    "axes = [keys.index(k) for k in [lx, ly, lz]]\n",
    "\n",
    "xy = np.meshgrid(*[stepping[i] for i in axes[:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce over the unselected dimensions and reorder them in `x-y-z` order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = cube.min(axis=tuple(np.delete(np.r_[:cube.ndim], axes)))\n",
    "\n",
    "# shuffle the dimensions: the axes in `reduce` are in\n",
    "#  natural order 0, 1, 2. The inner `argsort` maps the\n",
    "#  original hi-dim axes to the `reduce` axes. The outer\n",
    "#  argmin tells `transposez how to re-shuffle the axes.\n",
    "reduced = reduced.transpose(np.argsort(np.argsort(axes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log-normalize the data cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.log2(reduced).copy()\n",
    "values -= values.min(keepdims=True)\n",
    "values /= values.max(keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the effects on rmse of the different parameters. Make an interactive 3d-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d', proj_type='ortho',\n",
    "                     xlabel=f\"{sx}({lx})\", ylabel=f\"{sy}({ly})\",\n",
    "                     zlabel=f\"{sz}({lz})\")\n",
    "\n",
    "(xx, yy), zz = xy, stepping[axes[-1]]\n",
    "xx = np.log10(xx) if sx == \"log\" else xx\n",
    "yy = np.log10(yy) if sy == \"log\" else yy\n",
    "zz = np.log10(zz) if sz == \"log\" else zz\n",
    "\n",
    "ax.view_init(30, 225)\n",
    "ax.set_zlim(zz.min(), zz.max())\n",
    "ax.set_title(f\"{lx}-{ly}-{lz}\")\n",
    "\n",
    "for i, zk in enumerate(zz):\n",
    "    layer = np.full_like(xy[0], zk, dtype=float)\n",
    "    ax.plot_surface(xx, yy, layer, alpha=0.5, lw=0, shade=False, rstride=1,\n",
    "                    cstride=1, facecolors=plt.cm.CMRmap(values[..., i].T))\n",
    "\n",
    "# end for\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"\"\"STOP!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some basic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.zeros_like(targets[:, :2])\n",
    "features[2:] = targets[:-2, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.erdos_renyi_graph(n_targets, 0.2, directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = nx.adjacency_matrix(G)\n",
    "adj = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the dynamics of the latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_cols = 3\n",
    "n_rows = (trmf.n_components + n_cols - 1) // n_cols\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 1.5*n_rows),\n",
    "                         sharex=True, sharey=False)\n",
    "\n",
    "for j, ax in zip(range(trmf.n_components), axes.flat):\n",
    "    ax.plot(factor_pasted[:-(n_ahead + n_horizon), j], lw=2)\n",
    "    ax.plot(factor_pasted[:-n_horizon, j], zorder=-1)\n",
    "    ax.plot(factor_pasted[:, j], zorder=-2, alpha=0.5)\n",
    "\n",
    "for ax in axes.flat[trmf.n_components:]:\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    ax.plot([0, len(factor_pasted)], [y_min, y_max], c=\"k\", lw=2, alpha=.25)\n",
    "    ax.plot([0, len(factor_pasted)], [y_max, y_min], c=\"k\", lw=2, alpha=.25)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
